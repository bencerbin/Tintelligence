{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ac48da",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f682fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchsummary import summary\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "jtplot.style(context=\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3126b053",
   "metadata": {},
   "source": [
    "## Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21736c21-6bf8-4d8f-af68-d7f5323581d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already extracted.\n"
     ]
    }
   ],
   "source": [
    "# Download download Tiny ImageNet directly into your Jupyter Notebook\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# set directory and download URL\n",
    "url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "output_dir = \"tiny-imagenet-200\"\n",
    "zip_filename = \"tiny-imagenet-200.zip\"\n",
    "\n",
    "# download zip file if it doesn't exist\n",
    "if not os.path.exists(zip_filename):\n",
    "    print(\"Downloading Tiny ImageNet...\")\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(zip_filename, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "# unzip if not already extracted\n",
    "if not os.path.exists(output_dir):\n",
    "    print(\"Extracting zip file...\")\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "    print(\"Extraction complete.\")\n",
    "else:\n",
    "    print(\"Already extracted.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95a5944d-c96f-4b3c-b302-eee38a478e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def convert_jpegs_to_bw(source_root, dest_root):\n",
    "    source_root = Path(source_root)\n",
    "    dest_root = Path(dest_root)\n",
    "\n",
    "    print(os.listdir(\"Tintelligence/notebooks\"))  # shows folders like 'tiny-imagenet-200'\n",
    "    print(os.listdir(\"Tintelligence/notebooks/tiny-imagenet-200/train\"))  # should show class folders\n",
    "\n",
    "\n",
    "    for root, dirs, files in os.walk(source_root):\n",
    "        for file in files:\n",
    "            print(\"new file doing thangs\")\n",
    "            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".jpeg\".upper(), \".jpg\".upper())):\n",
    "                source_path = Path(root) / file\n",
    "                relative_path = source_path.relative_to(source_root)\n",
    "                dest_path = dest_root / relative_path\n",
    "\n",
    "                # Ensure destination directory exists\n",
    "                dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Convert image to grayscale and save\n",
    "                try:\n",
    "                    img = Image.open(source_path).convert(\"L\")\n",
    "                    img.save(dest_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {source_path}: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# source_folder = \"your/source/folder/path\"\n",
    "# destination_folder = \"your/destination/folder/path\"\n",
    "\n",
    "# convert_jpegs_to_bw(source_folder, destination_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ade84a2-3543-4ad1-9d1f-8e9d0196a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_full_to_grayscale(\n",
    "#     original_root=\"tiny-imagenet-200\",\n",
    "#     grayscale_root=\"tiny-imagenet-200-grayscale\"\n",
    "# ):\n",
    "#     from PIL import Image\n",
    "#     import os\n",
    "#     from tqdm.notebook import tqdm\n",
    "\n",
    "#     if os.path.exists(grayscale_root):\n",
    "#         print(f\"‚úÖ Grayscale dataset already exists at: {os.path.abspath(grayscale_root)} ‚Äî skipping conversion.\")\n",
    "#         return\n",
    "\n",
    "#     print(\"üöÄ Starting full grayscale dataset conversion...\")\n",
    "    \n",
    "#     for split in [\"train\", \"val\", \"test\"]:\n",
    "#         orig_split_path = os.path.join(original_root, split)\n",
    "#         gray_split_path = os.path.join(grayscale_root, split)\n",
    "#         print(f\"üìÇ Processing {split}...\")\n",
    "\n",
    "#         for root, dirs, files in os.walk(orig_split_path):\n",
    "#             # Figure out corresponding grayscale path\n",
    "#             rel_path = os.path.relpath(root, original_root)\n",
    "#             gray_root = os.path.join(grayscale_root, rel_path)\n",
    "\n",
    "#             os.makedirs(gray_root, exist_ok=True)\n",
    "\n",
    "#             for fname in files:\n",
    "#                 if not fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "#                     continue  # skip text files like annotations\n",
    "\n",
    "#                 orig_file = os.path.join(root, fname)\n",
    "#                 gray_file = os.path.join(gray_root, fname)\n",
    "\n",
    "#                 try:\n",
    "#                     img = Image.open(orig_file).convert('L')\n",
    "#                     img.save(gray_file)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"‚ùå Error converting {orig_file}: {e}\")\n",
    "\n",
    "#     print(\"‚úÖ All grayscale folders created at:\", os.path.abspath(grayscale_root))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37588791-8392-4bf6-8f89-80743ec07182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happening\n"
     ]
    }
   ],
   "source": [
    "# convert_to_grayscale_dataset()\n",
    "\n",
    "source_folder = \"Tintelligence/notebooks/tiny-imagenet-200/train\"\n",
    "destination_folder = \"Tintelligence/notebooks/tiny-imagenet-200-grayscale/train\"\n",
    "convert_jpegs_to_bw(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c55a9b-f0ea-421f-88b7-1503f293743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose a sample image from Tiny ImageNet\n",
    "sample_img_path = os.path.join(\"tiny-imagenet-200\", \"train\", \"n01443537\", \"images\")\n",
    "sample_img = os.listdir(sample_img_path)[0]\n",
    "full_img_path = os.path.join(sample_img_path, sample_img)\n",
    "\n",
    "# Load images\n",
    "img_color = Image.open(full_img_path).convert('RGB')\n",
    "img_gray = img_color.convert('L')\n",
    "\n",
    "# Plot side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "axs[0].imshow(img_color)\n",
    "axs[0].set_title(\"Original Color\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(img_gray, cmap='gray')\n",
    "axs[1].set_title(\"Grayscale Version\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89474e47-8c73-4c9b-993a-3f84954b934b",
   "metadata": {},
   "source": [
    "## Dataset Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d020e80-faad-41d6-aed0-fd8a8c1d2d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, grayscale_dir, color_dir, transform_input=None, transform_target=None):\n",
    "        self.grayscale_dir = grayscale_dir\n",
    "        self.color_dir = color_dir\n",
    "        self.transform_input = transform_input\n",
    "        self.transform_target = transform_target\n",
    "        self.samples = []\n",
    "\n",
    "        for class_name in os.listdir(grayscale_dir):\n",
    "            gray_class_path = os.path.join(grayscale_dir, class_name, \"images\")\n",
    "            color_class_path = os.path.join(color_dir, class_name, \"images\")\n",
    "\n",
    "            if not os.path.isdir(gray_class_path):\n",
    "                continue\n",
    "\n",
    "            for img_name in os.listdir(gray_class_path):\n",
    "                gray_img_path = os.path.join(gray_class_path, img_name)\n",
    "                color_img_path = os.path.join(color_class_path, img_name)\n",
    "\n",
    "                if os.path.exists(color_img_path):\n",
    "                    self.samples.append((gray_img_path, color_img_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gray_path, color_path = self.samples[idx]\n",
    "        gray = Image.open(gray_path).convert(\"L\")\n",
    "        color = Image.open(color_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform_input:\n",
    "            gray = self.transform_input(gray)\n",
    "        if self.transform_target:\n",
    "            color = self.transform_target(color)\n",
    "\n",
    "        return gray, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f315f92-a9ed-488a-9336-75eaf7037862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colorization_loaders(grayscale_path, color_path, batch_size=32):\n",
    "    transform_input = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    transform_target = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    dataset = ColorizationDataset(grayscale_path, color_path, transform_input, transform_target)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ada792-895b-4fdd-9831-8cd120103a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /home/jmpb2020/Tintelligence/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f729ddcb-6da2-435b-8726-6a5d693e3091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grayscale Directory Exists: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Grayscale Directory Exists:\", os.path.exists(\"tiny-imagenet-200-grayscale/train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52dd9a38-d8a9-4af3-8da6-9c6249282c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grayscale root exists: False\n",
      "Grayscale train exists: False\n",
      "Sample class folders: ‚ùå No /train folder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Grayscale root exists:\", os.path.exists(\"../tiny-imagenet-200-grayscale\"))\n",
    "print(\"Grayscale train exists:\", os.path.exists(\"../tiny-imagenet-200-grayscale/train\"))\n",
    "print(\"Sample class folders:\", os.listdir(\"../tiny-imagenet-200-grayscale/train\")[:5] if os.path.exists(\"../tiny-imagenet-200-grayscale/train\") else \"‚ùå No /train folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c40c29f-a1ec-4344-85a4-bb2c089f61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_path = \"./tiny-imagenet-200-grayscale/train\"\n",
    "color_path = \"./tiny-imagenet-200/train\"\n",
    "train_loader = get_colorization_loaders(grayscale_path, color_path, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f39bbb17-6b22-439a-a1bb-85f780ae0a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"tiny-imagenet-200-grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b14d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_cifar10_data_loaders(path, batch_size, valid_batch_size=0):\n",
    "#     # TINT TODO: Change this to utilize some of the training progress we made in bw_colorizer\n",
    "\n",
    "#     # Data specific transforms\n",
    "#     data_std = (0.2470, 0.2435, 0.2616)\n",
    "#     data_mean = (0.4914, 0.4822, 0.4465)\n",
    "#     xforms = Compose([ToTensor(), Normalize(data_mean, data_std)])\n",
    "\n",
    "#     # Training dataset and loader\n",
    "#     train_dataset = CIFAR10(root=path, train=True, download=True, transform=xforms)\n",
    "\n",
    "#     # Set the batch size to N if batch_size is 0\n",
    "#     tbs = len(train_dataset) if batch_size == 0 else batch_size\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=tbs, shuffle=True)\n",
    "\n",
    "#     valid_dataset = CIFAR10(root=path, train=False, download=True, transform=xforms)\n",
    "\n",
    "#     # Set the batch size to N if batch_size is 0\n",
    "#     vbs = len(valid_dataset) if valid_batch_size == 0 else valid_batch_size\n",
    "#     valid_loader = DataLoader(valid_dataset, batch_size=vbs, shuffle=True)\n",
    "\n",
    "#     return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd7c5a",
   "metadata": {},
   "source": [
    "## Training Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24a9968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(mb, loader, device, model, criterion, optimizer):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    num_batches = len(loader)\n",
    "    dataiterator = iter(loader)\n",
    "\n",
    "    for batch in progress_bar(range(num_batches), parent=mb):\n",
    "\n",
    "        mb.child.comment = \"Training\"\n",
    "\n",
    "        # Grab the batch of data and send it to the correct device\n",
    "        X, Y = next(dataiterator)\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        # Compute the output\n",
    "        output = model(X)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output, Y)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73463196",
   "metadata": {},
   "source": [
    "## Validation Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "103de938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(mb, loader, device, model, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    num_correct = 0\n",
    "\n",
    "    num_classes = len(loader.dataset.classes)\n",
    "    class_correct = [0] * num_classes\n",
    "    class_total = [0] * num_classes\n",
    "\n",
    "    N = len(loader.dataset)\n",
    "    num_batches = len(loader)\n",
    "    dataiterator = iter(loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        batches = range(num_batches)\n",
    "        batches = progress_bar(batches, parent=mb) if mb else batches\n",
    "        for batch in batches:\n",
    "\n",
    "            if mb:\n",
    "                mb.child.comment = f\"Validation\"\n",
    "\n",
    "            # Grab the batch of data and send it to the correct device\n",
    "            X, Y = next(dataiterator)\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "            output = model(X)\n",
    "\n",
    "            loss = criterion(output, Y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Convert network output into predictions (one-hot -> number)\n",
    "            predictions = output.argmax(dim=1)\n",
    "\n",
    "            # Sum up total number that were correct\n",
    "            comparisons = predictions == Y\n",
    "            num_correct += comparisons.type(torch.float).sum().item()\n",
    "\n",
    "            # Sum up number of correct per class\n",
    "            for result, clss in zip(comparisons, Y):\n",
    "                class_correct[clss] += result.item()\n",
    "                class_total[clss] += 1\n",
    "\n",
    "    accuracy = 100 * (num_correct / N)\n",
    "    accuracies = {\n",
    "        clss: 100 * class_correct[clss] / class_total[clss]\n",
    "        for clss in range(num_classes)\n",
    "    }\n",
    "\n",
    "    return losses, accuracy, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db11651d",
   "metadata": {},
   "source": [
    "## Loss Plotting Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2ac9b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_plots(mb, train_losses, valid_losses, epoch, num_epochs):\n",
    "\n",
    "    # Update plot data\n",
    "    max_loss = max(max(train_losses), max(valid_losses))\n",
    "    min_loss = min(min(train_losses), min(valid_losses))\n",
    "\n",
    "    x_margin = 0.2\n",
    "    x_bounds = [0 - x_margin, num_epochs + x_margin]\n",
    "\n",
    "    y_margin = 0.1\n",
    "    y_bounds = [min_loss - y_margin, max_loss + y_margin]\n",
    "\n",
    "    train_xaxis = torch.linspace(0, epoch + 1, len(train_losses))\n",
    "    valid_xaxis = torch.linspace(0, epoch + 1, len(valid_losses))\n",
    "    graph_data = [[train_xaxis, train_losses], [valid_xaxis, valid_losses]]\n",
    "\n",
    "    mb.update_graph(graph_data, x_bounds, y_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5041f60d",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e18e3af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'cuda' device.\n"
     ]
    }
   ],
   "source": [
    "# TODO: tune the training batch size\n",
    "train_batch_size = 128\n",
    "\n",
    "# Let's use some shared space for the data (so that we don't have copies\n",
    "# sitting around everywhere)\n",
    "data_path = \"~/data\"\n",
    "\n",
    "# Use the GPUs if they are available\n",
    "# TODO: if you run into GPU memory errors you should set device to \"cpu\" and restart the notebook\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using '{device}' device.\")\n",
    "\n",
    "valid_batch_size = 5000\n",
    "grayscale_path = \"./tiny-imagenet-200-grayscale/train\"\n",
    "color_path = \"./tiny-imagenet-200/train\"\n",
    "train_loader = get_colorization_loaders(grayscale_path, color_path, batch_size=8)\n",
    "\n",
    "# Input and output sizes depend on data\n",
    "class_names = sorted(os.listdir(grayscale_path))\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b13ca31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grab a bunch of images and change the range to [0, 1]\n",
    "# nprint = 64\n",
    "# images = torch.tensor(train_loader.dataset.data[:nprint] / 255)\n",
    "# targets = train_loader.dataset.targets[:nprint]\n",
    "# labels = [f\"{class_names[target]:>10}\" for target in targets]\n",
    "\n",
    "# # Create a grid of the images (make_grid expects (BxCxHxW))\n",
    "# image_grid = make_grid(images.permute(0, 3, 1, 2))\n",
    "\n",
    "# _, ax = plt.subplots(figsize=(16, 16))\n",
    "# ax.imshow(image_grid.permute(1, 2, 0))\n",
    "# ax.grid(None)\n",
    "\n",
    "# images_per_row = int(nprint ** 0.5)\n",
    "# for row in range(images_per_row):\n",
    "#     start_index = row * images_per_row\n",
    "#     print(\" \".join(labels[start_index : start_index + images_per_row]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d526f6",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b57cc453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super().__init__()\n",
    "\n",
    "        # The first \"layer\" just rearranges an image into a column vector\n",
    "        first_layer = nn.Flatten()\n",
    "\n",
    "        # The hidden layers include:\n",
    "        # 1. a linear component (computing Z) and\n",
    "        # 2. a non-linear comonent (computing A)\n",
    "        # TODO: add dropout and/or batch normalization\n",
    "        hidden_layers = [\n",
    "            nn.Sequential(nn.Linear(nlminus1, nl), nn.ReLU())\n",
    "            for nl, nlminus1 in zip(layer_sizes[1:-1], layer_sizes)\n",
    "        ]\n",
    "\n",
    "        # The output layer must be Linear without an activation. See:\n",
    "        #   https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "        output_layer = nn.Linear(layer_sizes[-2], layer_sizes[-1])\n",
    "\n",
    "        # Group all layers into the sequential container\n",
    "        all_layers = [first_layer, *hidden_layers, output_layer]\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.layers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1616b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # TODO: create layers here\n",
    "\n",
    "        # Early CNNs had the following structure:\n",
    "        #    X -> [[Conv2d -> ReLU] x N -> MaxPool2d] x M\n",
    "        #      -> [Linear -> ReLU] x K -> Linear\n",
    "        #   Where\n",
    "        #     0 ‚â§ N ‚â§ 3\n",
    "        #     0 ‚â§ M ‚â§ 3\n",
    "        #     0 ‚â§ K < 3\n",
    "        #\n",
    "        # The \"[[Conv2d -> ReLU] x N -> MaxPool2d] x M\" part extracts\n",
    "        # useful features, and the \"[Linear -> ReLU] x K -> Linear\" part\n",
    "        # performs the classification.\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Conv layer 1: (3 input channels, 32 output channels)\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # downsample by 2\n",
    "\n",
    "            # Conv layer 2: (32 input channels, 64 output channels)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # downsample again\n",
    "        )\n",
    "\n",
    "        # After two max-pool layers on 32x32 input ‚Üí 8x8 feature maps\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  # flatten the output from conv layers\n",
    "            nn.Linear(64 * 8 * 8, 128),  # fully connected layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)  # 10 output classes for CIFAR-10\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        # TODO: implement forward pass here\n",
    "        X = self.conv_layers(X)\n",
    "        X = self.fc_layers(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "289e3507-b5c1-42dd-965d-4c9a9d52bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Simple CNN\n",
    "class ColorizationCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),  # grayscale input\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 2, stride=2),  # 3-channel output\n",
    "            nn.Sigmoid()  # values in [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c5d34fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "‚îú‚îÄSequential: 1-1                        --\n",
      "|    ‚îî‚îÄConv2d: 2-1                       640\n",
      "|    ‚îî‚îÄReLU: 2-2                         --\n",
      "|    ‚îî‚îÄMaxPool2d: 2-3                    --\n",
      "|    ‚îî‚îÄConv2d: 2-4                       73,856\n",
      "|    ‚îî‚îÄReLU: 2-5                         --\n",
      "|    ‚îî‚îÄMaxPool2d: 2-6                    --\n",
      "‚îú‚îÄSequential: 1-2                        --\n",
      "|    ‚îî‚îÄConvTranspose2d: 2-7              32,832\n",
      "|    ‚îî‚îÄReLU: 2-8                         --\n",
      "|    ‚îî‚îÄConvTranspose2d: 2-9              771\n",
      "|    ‚îî‚îÄSigmoid: 2-10                     --\n",
      "=================================================================\n",
      "Total params: 108,099\n",
      "Trainable params: 108,099\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# TODO: try out different network widths and depths\n",
    "# neurons_per_hidden_layer = [1024, 512, 256]\n",
    "# layer_sizes = [num_features, *neurons_per_hidden_layer, num_classes]\n",
    "# model = NeuralNetwork(layer_sizes).to(device)\n",
    "\n",
    "# TODO: complete the CNN class in the cell above this one and then uncomment this line\n",
    "# model = CNN().to(device)\n",
    "\n",
    "# TODO: use an off-the-shell model from PyTorch\n",
    "# from torchvision.models import ...\n",
    "# model = ...\n",
    "\n",
    "# TINT TODO: make the output have 3 nodes.\n",
    "# from torchvision.models import resnet18\n",
    "# model = resnet18(num_classes=num_classes).to(device)\n",
    "\n",
    "# summary(model)\n",
    "\n",
    "#TINT\n",
    "# Instantiate the model\n",
    "model = ColorizationCNN().to(device)\n",
    "summary(model)\n",
    "# pixel-wise loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# TODO: try out different Adam hyperparameters\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c38b707-75ea-4233-ab14-5212da8c7acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output shape: torch.Size([8, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Test single batch\n",
    "\n",
    "gray_batch, color_batch = next(iter(train_loader))\n",
    "gray_batch, color_batch = gray_batch.to(device), color_batch.to(device)\n",
    "output = model(gray_batch)\n",
    "print(\"‚úÖ Output shape:\", output.shape)  # Should be [batch_size, 3, 64, 64]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd179cb",
   "metadata": {},
   "source": [
    "## Training and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcd7b615",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m mb\u001b[38;5;241m.\u001b[39mmain_bar\u001b[38;5;241m.\u001b[39mcomment \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Loss and accuracy prior to training\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m vl, accuracy, _ \u001b[38;5;241m=\u001b[39m validate(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[43mvalid_loader\u001b[49m, device, model, criterion)\n\u001b[1;32m     15\u001b[0m valid_losses\u001b[38;5;241m.\u001b[39mextend(vl)\n\u001b[1;32m     16\u001b[0m accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: tune the number of epochs\n",
    "num_epochs = 3\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "accuracies = []\n",
    "\n",
    "# A master bar for fancy output progress\n",
    "mb = master_bar(range(num_epochs))\n",
    "mb.names = [\"Train Loss\", \"Valid Loss\"]\n",
    "mb.main_bar.comment = f\"Epochs\"\n",
    "\n",
    "# Loss and accuracy prior to training\n",
    "vl, accuracy, _ = validate(None, valid_loader, device, model, criterion)\n",
    "valid_losses.extend(vl)\n",
    "accuracies.append(accuracy)\n",
    "\n",
    "for epoch in mb:\n",
    "\n",
    "    tl = train_one_epoch(mb, train_loader, device, model, criterion, optimizer)\n",
    "    train_losses.extend(tl)\n",
    "\n",
    "    vl, accuracy, acc_by_class = validate(mb, valid_loader, device, model, criterion)\n",
    "    valid_losses.extend(vl)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    update_plots(mb, train_losses, valid_losses, epoch, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665447d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracies, '--o')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.xticks(range(num_epochs+1))\n",
    "plt.ylim([0, 100])\n",
    "\n",
    "max_name_len = max(len(name) for name in class_names)\n",
    "\n",
    "print(\"Accuracy per class\")\n",
    "for clss in acc_by_class:\n",
    "    class_name = class_names[clss]\n",
    "    class_accuracy = acc_by_class[clss]\n",
    "    print(f\"  {class_name:>{max_name_len+2}}: {class_accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3681fc-9d47-45f6-b8d2-c9433b60c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = []\n",
    "y_preds = []\n",
    "model.to(device)\n",
    "for x, y in valid_loader:\n",
    "    y_trues.append(y.cpu())\n",
    "    y_preds.append(model(x.to(device)).argmax(dim=1).cpu())\n",
    "\n",
    "y_true = torch.hstack(y_trues)\n",
    "y_pred = torch.hstack(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8a494-fd98-483a-b792-98ff40b05af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names).plot();\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58043e-1b64-4f21-93e0-4c744bfbc652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Take the three outputs and reconstruct an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc6623-85b8-4dbb-9b11-9116b6ba874b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python3 (cs152)",
   "language": "python",
   "name": "cs152"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
